{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[6.1]토큰화와 원-핫 인코딩.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Egeensbv_3f",
        "colab_type": "text"
      },
      "source": [
        "# 텍스트 데이터란?\n",
        "\n",
        "\n",
        "\n",
        "*   단어의 시퀀스나 문자의 시퀀스 형태로 이루어진 데이터이다.\n",
        "*   딥러닝 모델은 텍스트 원본을 다루지 못하고 수치형 텐서만 다룰 수 있다.\n",
        "\n",
        "\n",
        "    ▣ 텍스트 벡터화(vectorizing text: 텍스트를 수치형 텐서로 변환하는 과정)\n",
        "\n",
        "    *   텍스트를 단어로 나누고 하나의 벡터로 변환한다.\n",
        "    *   텍스트를 문자로 나누고 하나의 벡터로 변환한다.\n",
        "    *   텍스트에서 단어나 문자의 n-gram(연속된 단어나 문자의 그룹)을 추출하여 각 n-gram을 하나의 벡터로  변환한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxxrxjf7xXto",
        "colab_type": "text"
      },
      "source": [
        "# 토큰화(Tokenization)와 벡터를 연결하는 방법\n",
        "\n",
        "*   토큰(Token) : 텍스트를 나누는 단위(단어, 문자, n-gram)\n",
        "*   토큰화(Tokenization) : 텍스트를 토큰으로 나누는 작업을 의미한다.\n",
        "\n",
        "*   토큰과 벡터를 연결하는 방법\n",
        "\n",
        " 1) 원-핫 인코딩(one-hot encoding)\n",
        "\n",
        " 2) 토큰 임베딩 또는 단어 임베딩\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAmWNsLj0o_3",
        "colab_type": "text"
      },
      "source": [
        "# 단어 원-핫 인코딩 예제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX_LCp8Ev7c5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a8d388e3-31b6-4e88-9e73-394014616bc0"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "samples=['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "token_index={}\n",
        "for sample in samples:\n",
        "  print(sample)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The cat sat on the mat.\n",
            "The dog ate my homework.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB-w5Tip1bjV",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   samples 안에 있는 각 문장들이 하나의 샘플이 된다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_jT2kRI1QGd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "70cef042-7ca4-41a8-e360-1dfbc312dd63"
      },
      "source": [
        "for sample in samples:\n",
        "  for word in sample.split():\n",
        "    print(word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The\n",
            "cat\n",
            "sat\n",
            "on\n",
            "the\n",
            "mat.\n",
            "The\n",
            "dog\n",
            "ate\n",
            "my\n",
            "homework.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75Nv9HmB1jMV",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   split( ) : 각 샘플을 토큰으로 나눠준다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb8QUwjl1alD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d5e892ff-8969-4758-80f0-598fd5866b0b"
      },
      "source": [
        "for sample in samples:\n",
        "  for word in sample.split():\n",
        "    if word not in token_index:\n",
        "      token_index[word]=len(token_index)+1\n",
        "\n",
        "print(token_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'The': 1, 'cat': 2, 'sat': 3, 'on': 4, 'the': 5, 'mat.': 6, 'dog': 7, 'ate': 8, 'my': 9, 'homework.': 10}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvWy5_EO2Mce",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "*   split( ) 으로 나눠진 각 단어마다 고유한 인덱스가 부여된다.\n",
        "*   인덱스 0은 사용하지 않으므로 len(token_index)에 '+1'을 해줘야한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ6HHRZQ24oG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "d56e1ff6-2679-4eb5-8575-ad2a6c281204"
      },
      "source": [
        "max_length=10\n",
        "\n",
        "results=np.zeros(shape=(len(samples), max_length, max(token_index.values())+1))\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeX5jpHe3ipG",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   shape ( len(samples), max_length, max(token_index.values( )) + 1)\n",
        "\n",
        " → (2, 10, 11)\n",
        "\n",
        "\n",
        "\n",
        "*   2 : 원-핫 인코딩을 해줘야하는 샘플(문장)의 개수\n",
        "*   10 : 각 샘플(문장)에서 10번째 단어까지만 사용한다.\n",
        "*   11 : token_index로 만들어진 value 개수 + 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV84KCUK45ql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "4e3ff5a0-9830-432c-9d36-4161ea81ea15"
      },
      "source": [
        "for i, sample in enumerate(samples):\n",
        "  for j, word in list(enumerate(sample.split()))[:max_length]:\n",
        "    index=token_index.get(word)\n",
        "    results[i,j,index]=1\n",
        "\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpMgA5NR5RwU",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "*   sample1: 'The' , 'cat' , 'sat' , 'on' , 'the' , 'mat'\n",
        "*   sample2: 'The' , 'dog' , 'ate' , 'my' , 'homework'\n",
        "*   {'The': 1, 'cat': 2, 'sat': 3, 'on': 4, 'the': 5, 'mat.': 6, 'dog': 7, 'ate': 8, 'my': 9, 'homework.': 10}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYae6aWb6V1V",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQMaajYK6LEG",
        "colab_type": "text"
      },
      "source": [
        "# 문자 원-핫 인코딩 예제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4SNgiap6YL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "\n",
        "samples=['The cat sat on the mat.', 'The dog ate my homework.']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0q0L78e6m6c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "45f42af1-e448-455d-f8d1-f5789a93f2ad"
      },
      "source": [
        "characters=string.printable\n",
        "print(characters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
            "\r\u000b\f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjPxakl36qRM",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   string.printable : 출력 가능한 모든 아스키(ASCII) 문자를 담고 있다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znVQbZ0S60Ib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "ea7f6e53-533f-4d3d-9cad-43452741638c"
      },
      "source": [
        "token_index=dict(zip(characters, range(1, len(characters) + 1)))\n",
        "print(token_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'0': 1, '1': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10, 'a': 11, 'b': 12, 'c': 13, 'd': 14, 'e': 15, 'f': 16, 'g': 17, 'h': 18, 'i': 19, 'j': 20, 'k': 21, 'l': 22, 'm': 23, 'n': 24, 'o': 25, 'p': 26, 'q': 27, 'r': 28, 's': 29, 't': 30, 'u': 31, 'v': 32, 'w': 33, 'x': 34, 'y': 35, 'z': 36, 'A': 37, 'B': 38, 'C': 39, 'D': 40, 'E': 41, 'F': 42, 'G': 43, 'H': 44, 'I': 45, 'J': 46, 'K': 47, 'L': 48, 'M': 49, 'N': 50, 'O': 51, 'P': 52, 'Q': 53, 'R': 54, 'S': 55, 'T': 56, 'U': 57, 'V': 58, 'W': 59, 'X': 60, 'Y': 61, 'Z': 62, '!': 63, '\"': 64, '#': 65, '$': 66, '%': 67, '&': 68, \"'\": 69, '(': 70, ')': 71, '*': 72, '+': 73, ',': 74, '-': 75, '.': 76, '/': 77, ':': 78, ';': 79, '<': 80, '=': 81, '>': 82, '?': 83, '@': 84, '[': 85, '\\\\': 86, ']': 87, '^': 88, '_': 89, '`': 90, '{': 91, '|': 92, '}': 93, '~': 94, ' ': 95, '\\t': 96, '\\n': 97, '\\r': 98, '\\x0b': 99, '\\x0c': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifqmmAUv7Kgn",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   dict를 이용하여 각 아스키(ASCII) 문자 마다 인덱스를 부여한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSA-fZFn7IUV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "1d6bced6-4154-4c86-93cc-a461b645cb76"
      },
      "source": [
        "max_length=50\n",
        "results=np.zeros((len(samples), max_length, max(token_index.values())+1))\n",
        "\n",
        "for i, sample in enumerate(samples):\n",
        "  for j, character in enumerate(sample):\n",
        "    index=token_index.get(character)\n",
        "    results[i,j,index]=1\n",
        "\n",
        "print(results[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IPNen-I9yU1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*  results[0][0]\n",
        "\n",
        "→ 첫번째 문장 'The cat sat on the mat.'   \n",
        "\n",
        "→ 첫번째 단어 'T'\n",
        "\n",
        "→ 'T': 56 (57번째 인덱스만 1이고 나머지는 0으로 출력된다.) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMrklE_6AKZ_",
        "colab_type": "text"
      },
      "source": [
        "# 케라스를 이용한 단어 원-핫 인코딩 예제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjO6xlKWAOPy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "43e79c8b-a79e-4516-a263-8045e1451fd9"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "samples=['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "\n",
        "tokenizer=Tokenizer(num_words=1000)   # 가장 빈도수가 높은 1,000개의 단어만 선택하도록 Tokenizer 객체를 만든다.\n",
        "tokenizer.fit_on_texts(samples)        # 단어 인덱스 구축\n",
        "\n",
        "sequences=tokenizer.texts_to_sequences(samples)  # 문자열을 정수 인덱스의 리스트로  변환한다.\n",
        "\n",
        "print(sequences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHqDtTPjA6tF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "317c83f7-1410-4282-b9da-9d866391749e"
      },
      "source": [
        "one_hot_results=tokenizer.texts_to_matrix(samples, mode='binary')\n",
        "print(one_hot_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74Z5gjWPBwmy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3825b6a4-e9c1-48ad-8d47-f45e38a24f47"
      },
      "source": [
        "print(len(one_hot_results[0]))\n",
        "print(len(one_hot_results[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpL2MFTJBEmK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a52c007e-cb8c-4bef-e85d-62bbceabf897"
      },
      "source": [
        "word_index=tokenizer.word_index\n",
        "print(word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 1, 'cat': 2, 'sat': 3, 'on': 4, 'mat': 5, 'dog': 6, 'ate': 7, 'my': 8, 'homework': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I0RUwbuB_jS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "741fb474-39c2-4c7b-d881-591711c85b4f"
      },
      "source": [
        "print('%s개의 고유한 토큰을 찾았습니다.' % len(word_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9개의 고유한 토큰을 찾았습니다.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}