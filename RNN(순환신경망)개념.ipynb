{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN(순환신경망)개념.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQGuitX9DIQo",
        "colab_type": "text"
      },
      "source": [
        "# 순환 신경망(Recurrent Neural Network, RNN)\n",
        "\n",
        "\n",
        "*   입력과 출력을 시퀀스 단위로 처리하는 모델이다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yU3IZEtuDyuc",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://wikidocs.net/images/page/22886/rnn_image1_ver2.PNG)\n",
        "\n",
        "x : 입력층의 입력 벡터\n",
        "y : 출력층의 출력 벡터\n",
        "(bias는 생략) \n",
        "\n",
        "\n",
        "*   은닉층에서 활성화 함수를 통해 결과를 내보내는 역할을 하는 노드를 셀(cell)이라고 한다.\n",
        "*   RNN셀은 기존의 셀과 달리, 이전의 값을 기억하려고 하는 메모리 역할을 수행한다.\n",
        "*   RNN셀은 각 시점(t-time step)에서 이전 시점(t-1)의 셀에서 나온 값을 입력으로 사용한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-wKhnhdE7Us",
        "colab_type": "text"
      },
      "source": [
        "# 순환 신경망의 장점\n",
        "\n",
        "\n",
        "*   입력과 출력의 길이를 다르게 설계할 수 있다.\n",
        "\n",
        "\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/22886/rnn_image3_ver2.PNG)\n",
        "\n",
        "  \n",
        "  1) 일 대 다(one-to-many) : 하나의 이미지 입력에 대해 사진의 제목(단어들의 시퀀스)을 출력하는 작업\n",
        "\n",
        "   2) 다 대 일(many-to-one) : 감성 분류(입력 문서가 긍정인지 부정인지), 스팸 메일 분류\n",
        "\n",
        "  3) 다 대 다(many-to-many) : 챗봇, 번역기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-cHoqdsG0wy",
        "colab_type": "text"
      },
      "source": [
        "# 순환 신경망의 단점\n",
        "\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/22888/lstm_image1_ver2.PNG)\n",
        "\n",
        "\n",
        "\n",
        "*   이전 계산 결과에 의존해서 출력을 하기 때문에, 시점(time step)이 길어질수록 앞의 정보가 뒤로 충분히 전달되지 못하는 현상이 발생한다.\n",
        "*   위의 그림에서 남색이 점차 옅어지는 것처럼, 뒤로 갈수록 x1의 정보량은 손실되고 전체 정보에 대한 영향력은 거의 의미가 없게 된다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gPdYgMCGW2r",
        "colab_type": "text"
      },
      "source": [
        "위의 RNN을 가장 단순한 형태의 RNN이라 하여, 바닐라 RNN(Vanilla RNN)이라 부른다.\n",
        "\n",
        "→ 바닐라 RNN의 한계(단점)를 극복하기 위하여 다양한 RNN 변형(ex. LSTM)이 등장하게 되었다."
      ]
    }
  ]
}