## 희소 표현(Sparse Representation)
- 원-핫 인코딩을 통해서 나온 벡터들은 표현하고자 하는 단어의 인덱스 값만 1이고, 나머지는 전부 0으로 표현된다.
- 이와 같이 벡터 또는 행렬의 값의 대부분이 0으로 표현되는 방법을 희소 표현(sparse representation)이라고 한다.

## 희소 표현의 문제점
- 단어의 개수가 늘어나면 차원도 한없이 커지게 된다.
- 만약 원-핫 인코딩으로 표현할 단어의 말뭉치(corpus)가 10,000개이면 벡터의 차원도 10,000이어야 한다.

      Ex) 강아지=[0 0 0 0 1 0 0 0 ... 0 ] # 1개의 1과 999개의 0

  → 이런 벡터 표현은 공간적 낭비를 일으키고, **단어의 의미를 담지 못한다는 단점**이 있다.

## 밀집 표현(Dense Representation)
- 벡터의 차원을 단어 집합(corpus) 크기로 정하지 않고, 사용자가 설정한 값으로 맞춰진다.

      Ex) 강아지=[0.2 1.8 1.1 -2.1 1.1 ... 2.8] # 인덱스의 개수는 128(=벡터의 차원은 128)

  → 0과 1로만 구성되어 있지 않고, 모든 값이 실수가 된다.

## 워드 임베딩(Word Embedding)
- 단어를 밀집 벡터(dense representation)의 형태로 표현하는 방법을 **워드 임베딩**이라 한다.
- 워드 임베딩 방법론으로는 LSA, Word2Vec, FastText, Glove 등이 있다.
- **kears.layers.Embedding()** : 단어를 랜덤한 값을 가지는 밀집 벡터로 변환해서 neural network의 가중치를 학습한다.
