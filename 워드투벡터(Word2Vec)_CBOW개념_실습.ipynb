{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "워드투벡터(Word2Vec)-CBOW개념-실습.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zCBs91TlNFg",
        "colab_type": "text"
      },
      "source": [
        "# 워드투벡터(Word2Vec)\n",
        "\n",
        "\n",
        "*   (원-핫 벡터와 달리) 단어 간 유사도를 반영할 수 있도록 단어의 의미를 벡터화 하는 방법이다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4Ur-k77mid_",
        "colab_type": "text"
      },
      "source": [
        "## CBOW(Continuous Bag of Words)\n",
        "- 주변에 있는 단어를 자기고 중간에 있는 단어들을 예측하는 방법이다.\n",
        "\n",
        "      The fat cat sat on the mat\n",
        "      {'The', 'fat', 'cat', 'on', 'the', 'mat'} → {'sat'}을 예측해야 한다.\n",
        "\n",
        "      # 예측해야 하는 단어('sat')를 중심 단어(center word)라 한다.\n",
        "      # 예측에 사용되는 단어들을 주변 단어(context word)라 한다.\n",
        "\n",
        "      # 중심 단어를 예측하기 위해서 앞,뒤로 몇개의 단어를 볼지 결정하고, 이 범위를 윈도우(window)라 한다.\n",
        "      # 윈도우의 크기 2 : 중심 단어('sat)를 예측하기 위해서 앞의 두 단어('fat', 'cat'), 뒤의 두 단어('on', 'the')를 참고한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr1ryKmhn6bn",
        "colab_type": "text"
      },
      "source": [
        "*  **슬라이딩 윈도우(sliding window)**: 윈도우를 계속 움직여가며, 주변 단어와 중심 단어를 바꿔가며 학습을 위한 데이터 셋을 만드는 방법이다.\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/22660/%EB%8B%A8%EC%96%B4.PNG)\n",
        "\n",
        "→ 위의 그림은 윈도우 크기를 2로 정하여 어떻게 슬라이딩 윈도우가 이루어지는 지를 보여주고 있다.\n",
        "\n",
        "→ 오른쪽 표와 같이, 워드투벡터에서 입력은 모두 원-핫 벡터가 되어야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LifSVmJps8_r",
        "colab_type": "text"
      },
      "source": [
        "# 워드투벡터 실습\n",
        "##[ 데이터 로드 및 전처리 ]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq6C_9SIqD7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from lxml import etree\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XPGSEcnqXgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "urllib.request.urlretrieve(\"https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&filename=ted_en-20160408.zip\", filename=\"ted_en-20160408.zip\")\n",
        "# 데이터 다운로드\n",
        "\n",
        "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
        "  target_text = etree.parse(z.open('ted_en-20160408.xml', 'r'))\n",
        "  parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
        "# xml 파일로부터 <content>와 </content> 사이의 내용만 가져온다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RljWl0WnqliN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d3bdae06-c9e9-4472-b942-5c56cb91155b"
      },
      "source": [
        "parse_text[:300] # 로드한 데이터에서 300개의 글자(character)만 출력"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Here are two reasons companies fail: they only do more of the same, or they only do what's new.\\nTo me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation. Both are necessary, but it can be too much of a good thing.\\nConsider Facit\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vCC1SzNq6Fc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOSJfRukrzy-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "dc5ffd26-8c32-4f66-f023-9112acf041f5"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NstfSoyprPMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent_text=sent_tokenize(content_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HmihJsIr660",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalized_text=[]\n",
        "for string in sent_text:\n",
        "  tokens=re.sub(r\"[^a-z0-9]+\", \" \", string.lower())  # 각 문장에 대해서 구두점 제거하고, 대문자를 소문자로 변환\n",
        "  normalized_text.append(tokens)\n",
        "\n",
        "result=[word_tokenize(sentence) for sentence in normalized_text]  # 각 문장에 대해서 NLTK를 이용하여 단어 토큰화 수행"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I55rmP2hsgz-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee76d7a5-08ec-435e-f6e1-600ecf99a265"
      },
      "source": [
        "print('총 샘플의 개수: {}'.format(len(result)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "총 샘플의 개수: 273424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYj0KFqPsp_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa28e6a1-eb5b-4825-a8b6-4de389cbf89f"
      },
      "source": [
        "for line in result[:1]:\n",
        "  print(line)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-8J8tb4svfM",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   상위 1개 문장 출력을 통해서, 문장에 대해 토큰화가 수행되었음을 확인할 수 있다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBnTKopLtFnE",
        "colab_type": "text"
      },
      "source": [
        "## [ Word2Vec 훈련시키기 ]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeV3dPYgtK2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "model=Word2Vec(sentences=result, size=100, window=5, min_count=5, workers=4, sg=0)\n",
        "\n",
        "# size : 임베딩 된 벡터의 차원\n",
        "# window : 컨텍스트 윈도우 크기\n",
        "# min_count : 단어의 최소 빈도수 제한(빈도가 적은 단어들은 학습하지 않는다.)\n",
        "# workers : 학습을 위한 프로세스 수\n",
        "# sg=0 : CBOW"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMQQ-4MztziD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "99c7a09e-b80f-4780-a700-2f86773ee519"
      },
      "source": [
        "# model.wv.most_similar: 입력한 단어에 대해서 가장 유사한 단어를 출력하는 모듈\n",
        "model_result = model.wv.most_similar(\"man\")\n",
        "print(model_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('woman', 0.8441615104675293), ('guy', 0.8088982105255127), ('lady', 0.7658368945121765), ('boy', 0.7520817518234253), ('girl', 0.742436408996582), ('soldier', 0.7382450103759766), ('gentleman', 0.7178536057472229), ('kid', 0.7093591690063477), ('poet', 0.6823942065238953), ('king', 0.6648910045623779)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs0770_NuNMx",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*  'man'과 유사한 단어로 {'woman', 'guy', 'lady', 'boy', 'girl', 'soldier', ... } 가 출력되는 것을 알 수 있다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qGvVcVfvoDM",
        "colab_type": "text"
      },
      "source": [
        "## [ Word2Vec 모델 저장하고 로드하기 ]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "togduPYavwHq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b0767f47-eb4f-46a6-db16-80d25778290b"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "model.wv.save_word2vec_format('eng_w2v')\n",
        "loaded_model=KeyedVectors.load_word2vec_format(\"eng_w2v\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}