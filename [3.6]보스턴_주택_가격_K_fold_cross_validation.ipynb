{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[3.6]보스턴 주택 가격 K-fold cross-validation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pDBdOnJQ7R0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a4454033-7a0a-43ec-b197-1c4a8beecfaa"
      },
      "source": [
        "from keras.datasets import boston_housing\n",
        "\n",
        "(train_data, train_targets), (test_data, test_targets)=boston_housing.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 6us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyFPhyNewRu2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "cc2ac300-75e7-406f-97c9-5b44bf3daa0c"
      },
      "source": [
        "print('train_data: ', train_data.shape)\n",
        "print('test_data: ', test_data.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data:  (404, 13)\n",
            "test_data:  (102, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0EiMsu9wqt7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "827e8e6f-bb35-42f9-9db8-e291d0688be4"
      },
      "source": [
        "train_data.shape[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pJ37P_c6dWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean=train_data.mean(axis=0)\n",
        "std=train_data.std(axis=0)\n",
        "\n",
        "train_data-=mean\n",
        "train_data/=std\n",
        "\n",
        "test_data-=mean\n",
        "test_data/=std"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjJYtTKLuSpJ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*  입력 데이터 feature들의 범위가 서로 다르므로, 스케일을 조정해주는 전처리 단계를 해줘야 한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esLu2LlC64ic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "def build_model():\n",
        "  model=models.Sequential()\n",
        "  model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='rmsprop',\n",
        "                loss='mse',\n",
        "                metrics=['mae'])\n",
        "  return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37I4JY_quB51",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   회귀에서는 손실 함수로 MSE(평균 제곱 오차), 평가 지표로 MAE(평균 절대 오차)를 주로 사용한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZSYWtNz7Y2K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dcd95bfa-d407-4174-a5b2-e07e01289420"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "k=4\n",
        "num_val_samples=len(train_data)//k\n",
        "\n",
        "print(num_val_samples)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTLq75-eEJ1h",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   기존의 train, validation, test set\n",
        "\n",
        "＊전체 training set을 (partial_x_train, x_val), (partial_y_train, y_val)로 나눠서 학습을 진행한다.\n",
        "\n",
        "\n",
        "\n",
        "    history=model.fit(partial_x_train,  partial_y_train, epcohs=20, batch_size=512, validation_data=(x_val,y_val))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDqVTorWGrn-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "  acc, loss, val_acc, val_loss 에 대해 그래프를 그려보고 과대적합(Overfitting)이 일어나는 지점을 확인한다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  만약 두번째 epoch 이후부터 training set에 과도하게 최적화 되었으면, epoch을 4까지 줄인다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  ＊최종 모델에 대해서 학습하므로, 원래의 전체 데이터(x_train, y_train) 에 대해서 학습(fit)을 진행한다.\n",
        "\n",
        "    model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
        "    test_loss, test_acc=model.evaluate(x_test,y_test)\n",
        "    model.predict(x_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0FwW1Q2Gxjz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   K-겹 검증에서의 train, validation, test set\n",
        "\n",
        "＊모델의 최종 검증 점수는 k개의 검증 점수의 평균이 된다.\n",
        "\n",
        "＊k개의 검증 점수 : 하나의 fold 에서의 'validation'은 모델의 성능을 평가하는 test set역할을 하므로 fit에서 validation_data를 사용하지 않는다.\n",
        "\n",
        "    model.fit(partial_train_data, partial_train_targets, epochs=100, batch_size=1)\n",
        "    val_mse, val_mae=model.evaluate(val_data, val_targets) \n",
        "\n",
        "*val_data, val_targets 가 위에서의 test set역할을 하므로 검증데이터에 대해서 'evaluate'를 한다.\n",
        "\n",
        "*모델 성능 평가를 위한 loss funtion으로 'mse', 성능 측정 매트릭스로 'mae'를 사용했다.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsEuhGSMoDrw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "43265e41-3bfa-4af8-b913-3b4322729ff2"
      },
      "source": [
        "num_epochs=100\n",
        "all_scores=[]\n",
        "\n",
        "for i in range(k):\n",
        "  print('처리중인 폴드 #',i)\n",
        "  val_data = train_data[i*num_val_samples: (i+1)*num_val_samples]\n",
        "  val_targets = train_targets[i*num_val_samples: (i+1)*num_val_samples]\n",
        "\n",
        "  partial_train_data = np.concatenate([train_data[:i*num_val_samples], train_data[(i+1)*num_val_samples:]], axis=0)   # np.concatenate: numpy 배열을 합쳐준다.\n",
        "  partial_train_targets = np.concatenate([train_targets[:i*num_val_samples], train_targets[(i+1)*num_val_samples:]], axis=0)\n",
        "\n",
        "  model=build_model()\n",
        "  model.fit(partial_train_data, partial_train_targets,\n",
        "            epochs=num_epochs,\n",
        "            batch_size=1,\n",
        "            verbose=0)    # verbose=0 이므로 훈련 과정이 출력되지 않는다.\n",
        "  val_mse, val_mae=model.evaluate(val_data, val_targets, verbose=0)\n",
        "  all_scores.append(val_mae)  # 검증 점수의 평균을 사용 할 것이기 때문에, 성능 측정 매트릭스의 점수를 저장한다."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "처리중인 폴드 # 0\n",
            "처리중인 폴드 # 1\n",
            "처리중인 폴드 # 2\n",
            "처리중인 폴드 # 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwvDmBuGpecQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85f78a9b-4897-4272-d78e-52951d4db034"
      },
      "source": [
        "np.mean(all_scores)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.434341609477997"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX4Jl3MUqVqI",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   (최종 모델의 검증 점수는) K개의 검증 점수의 평균이다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN-P-37Qs3Nk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2bad2d56-d07a-4208-9659-c1023c642b08"
      },
      "source": [
        "model=build_model()\n",
        "model.fit(train_data, train_targets,\n",
        "          epochs=80,              # 'MAE'그래프를 그려보면, 80번째 epoch 이후부터 과대적합이 시작되는 것을 확인할 수 있다.\n",
        "          batch_size=16,\n",
        "          verbose=0)\n",
        "\n",
        "test_mse_score, test_mae_score=model.evaluate(test_data, test_targets)\n",
        "\n",
        "print(test_mae_score)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 0s 176us/step\n",
            "2.52256441116333\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}