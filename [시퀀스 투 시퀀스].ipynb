{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[시퀀스 투 시퀀스].ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN+YTFMfVxZzyD9cfmEKkHl"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WejJvim5Bf5x","colab_type":"text"},"source":["# [시퀀스-투-시퀀스(Sequence-to- Sequence)]\n","\n","\n","\n","*   입력된 시퀀스로부터 다른 도메인의 시퀀스를 출력하는 모델이다.\n"]},{"cell_type":"markdown","metadata":{"id":"lrVctWhRrr-y","colab_type":"text"},"source":["![대체 텍스트](https://wikidocs.net/images/page/24996/seq2seq%EB%AA%A8%EB%8D%B811.PNG)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"P7ANBcFtryHA","colab_type":"text"},"source":["(시퀀스-투-시퀀스가 사용되는 여러 분야 중 하나인 **기계 번역**에서의 test 과정)\n","\n","*   시퀀스-투-시퀀스는 크게 두 개의 아키텍처( 인코더 / 디코더 )로 구성된다.\n","\n","*   **인코더**: 문장의 모든 단어들을 순차적으로 입력받아서 하나의 벡터, 컨텍스트 벡터(context vector)로 만들어준다.\n","\n","*   **디코더**: 인코더로 부터 전달된 컨텍스트 벡터를 받아서 번역된 단어를 순차적으로 출력해준다.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZRs4rwnFtRGj","colab_type":"text"},"source":["![대체 텍스트](https://wikidocs.net/images/page/24996/%EC%9D%B8%EC%BD%94%EB%8D%94%EB%94%94%EC%BD%94%EB%8D%94%EB%AA%A8%EB%8D%B8.PNG)\n"]},{"cell_type":"markdown","metadata":{"id":"8XRwWP7dtULJ","colab_type":"text"},"source":["\n","\n","*   인코더/디코더 아키텍처의 내부는 두 개의 RNN 아키텍처로 구성되어 있다.\n","\n","*   인코더\n","\n","        1. 입력된 문장이 토큰화를 통해 단어로 쪼개진다.\n","        2. 이 때, 쪼개진 단어 토큰 각각은 RNN 셀 각 시점의 입력이 된다.\n","        3. 마지막 RNN 셀의 은닉 상태를 디코더로 넘겨주는데, 이를 '컨텍스트 벡터' 라고 한다.\n","\n","\n","\n","*   디코더\n","\n","        1. 전달 받은 컨텍스트 벡터가 디코더 RNN 셀의 첫번째 은닉 상태로 사용된다.\n","        2. 문자의 시작을 의미하는 심볼 < sos > 가 입력된다.\n","        3. 다음에 등장할 확률이 높은 단어를 예측한다.\n","        4. 예측된 단어를 다음 시점의 RNN 셀의 입력으로 들어간다.\n","        5. 문장의 끝을 의미하는 심볼 < eos >가 입력될 때 까지 3,4번의 과정을 반복한다.\n","\n","\n","\n"]}]}